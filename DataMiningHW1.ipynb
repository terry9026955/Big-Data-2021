{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b87c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.13:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#檢查有無安裝好spark (我使用pyspark)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439fa92",
   "metadata": {},
   "source": [
    "//一開始直接讀textfile資料會讀失敗\n",
    "需要先設定好header、delimiter、inferSchema、csv路徑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057acd4",
   "metadata": {},
   "source": [
    "//以下為讀進textfile轉為dataframe\n",
    "經過以下修改後才可以把textfile讀成正確的dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8012e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+---------------------+-------+----------------+--------------+--------------+--------------+\n",
      "|      Date|    Time|Global_active_power|Global_reactive_power|Voltage|Global_intensity|Sub_metering_1|Sub_metering_2|Sub_metering_3|\n",
      "+----------+--------+-------------------+---------------------+-------+----------------+--------------+--------------+--------------+\n",
      "|16/12/2006|17:24:00|              4.216|                0.418|234.840|          18.400|         0.000|         1.000|          17.0|\n",
      "|16/12/2006|17:25:00|              5.360|                0.436|233.630|          23.000|         0.000|         1.000|          16.0|\n",
      "|16/12/2006|17:26:00|              5.374|                0.498|233.290|          23.000|         0.000|         2.000|          17.0|\n",
      "|16/12/2006|17:27:00|              5.388|                0.502|233.740|          23.000|         0.000|         1.000|          17.0|\n",
      "|16/12/2006|17:28:00|              3.666|                0.528|235.680|          15.800|         0.000|         1.000|          17.0|\n",
      "|16/12/2006|17:29:00|              3.520|                0.522|235.020|          15.000|         0.000|         2.000|          17.0|\n",
      "|16/12/2006|17:30:00|              3.702|                0.520|235.090|          15.800|         0.000|         1.000|          17.0|\n",
      "|16/12/2006|17:31:00|              3.700|                0.520|235.220|          15.800|         0.000|         1.000|          17.0|\n",
      "|16/12/2006|17:32:00|              3.668|                0.510|233.990|          15.800|         0.000|         1.000|          17.0|\n",
      "|16/12/2006|17:33:00|              3.662|                0.510|233.860|          15.800|         0.000|         2.000|          16.0|\n",
      "|16/12/2006|17:34:00|              4.448|                0.498|232.860|          19.600|         0.000|         1.000|          17.0|\n",
      "|16/12/2006|17:35:00|              5.412|                0.470|232.780|          23.200|         0.000|         1.000|          17.0|\n",
      "|16/12/2006|17:36:00|              5.224|                0.478|232.990|          22.400|         0.000|         1.000|          16.0|\n",
      "|16/12/2006|17:37:00|              5.268|                0.398|232.910|          22.600|         0.000|         2.000|          17.0|\n",
      "|16/12/2006|17:38:00|              4.054|                0.422|235.240|          17.600|         0.000|         1.000|          17.0|\n",
      "|16/12/2006|17:39:00|              3.384|                0.282|237.140|          14.200|         0.000|         0.000|          17.0|\n",
      "|16/12/2006|17:40:00|              3.270|                0.152|236.730|          13.800|         0.000|         0.000|          17.0|\n",
      "|16/12/2006|17:41:00|              3.430|                0.156|237.060|          14.400|         0.000|         0.000|          17.0|\n",
      "|16/12/2006|17:42:00|              3.266|                0.000|237.130|          13.800|         0.000|         0.000|          18.0|\n",
      "|16/12/2006|17:43:00|              3.728|                0.000|235.840|          16.400|         0.000|         0.000|          17.0|\n",
      "+----------+--------+-------------------+---------------------+-------+----------------+--------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#先讀資料進來\n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"C://Users//user//Desktop//household_power_consumption//household_power_consumption.txt\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e08dcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#把該import的都先import進來\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c14e51",
   "metadata": {},
   "source": [
    "【30pt】作業Part1: 算出以下四個header(column)個別的min、max、count值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c562713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------+--------------------------+\n",
      "|min(Global_active_power)|max(Global_active_power)|count(Global_active_power)|\n",
      "+------------------------+------------------------+--------------------------+\n",
      "|                   0.076|                   9.994|                   2049280|\n",
      "+------------------------+------------------------+--------------------------+\n",
      "\n",
      "+--------------------------+--------------------------+----------------------------+\n",
      "|min(Global_reactive_power)|max(Global_reactive_power)|count(Global_reactive_power)|\n",
      "+--------------------------+--------------------------+----------------------------+\n",
      "|                     0.000|                     1.390|                     2049280|\n",
      "+--------------------------+--------------------------+----------------------------+\n",
      "\n",
      "+------------+------------+--------------+\n",
      "|min(Voltage)|max(Voltage)|count(Voltage)|\n",
      "+------------+------------+--------------+\n",
      "|     223.200|     254.150|       2049280|\n",
      "+------------+------------+--------------+\n",
      "\n",
      "+---------------------+---------------------+-----------------------+\n",
      "|min(Global_intensity)|max(Global_intensity)|count(Global_intensity)|\n",
      "+---------------------+---------------------+-----------------------+\n",
      "|                0.200|                9.800|                2049280|\n",
      "+---------------------+---------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Global_active_power\n",
    "df_new = df.filter(df.Global_active_power != '?') #把這個column中的'?'值給過濾掉才不會輸出'?'\n",
    "df_new.agg(min(col(\"Global_active_power\")), max(col(\"Global_active_power\")), count(col(\"Global_active_power\"))).show()\n",
    "\n",
    "#Global_reactive_power\n",
    "df_new2 = df.filter(df.Voltage != '?')\n",
    "df_new2.agg(min(col(\"Global_reactive_power\")), max(col(\"Global_reactive_power\")), count(col(\"Global_reactive_power\"))).show()\n",
    "\n",
    "#Voltage\n",
    "df_new3 = df.filter(df.Voltage != '?')\n",
    "df_new3.agg(min(col(\"Voltage\")), max(col(\"Voltage\")), count(col(\"Voltage\"))).show()\n",
    "\n",
    "#Global_intensity\n",
    "df_new4 = df.filter(df.Global_intensity != '?')\n",
    "df_new4.agg(min(col(\"Global_intensity\")), max(col(\"Global_intensity\")), count(col(\"Global_intensity\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a6f50",
   "metadata": {},
   "source": [
    "【30pt】作業Part2: 輸出上述這些header(column)的mean、standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31a7e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------------------+\n",
      "|avg(Global_active_power)|stddev_samp(Global_active_power)|\n",
      "+------------------------+--------------------------------+\n",
      "|1.0916150365007122      |1.0572941610939701              |\n",
      "+------------------------+--------------------------------+\n",
      "\n",
      "+--------------------------+----------------------------------+\n",
      "|avg(Global_reactive_power)|stddev_samp(Global_reactive_power)|\n",
      "+--------------------------+----------------------------------+\n",
      "|0.12371447630388838       |0.1127219795507155                |\n",
      "+--------------------------+----------------------------------+\n",
      "\n",
      "+-----------------+--------------------+\n",
      "|avg(Voltage)     |stddev_samp(Voltage)|\n",
      "+-----------------+--------------------+\n",
      "|240.8398579745544|3.2399866790098937  |\n",
      "+-----------------+--------------------+\n",
      "\n",
      "+---------------------+-----------------------------+\n",
      "|avg(Global_intensity)|stddev_samp(Global_intensity)|\n",
      "+---------------------+-----------------------------+\n",
      "|4.627759310588417    |4.444396259786192            |\n",
      "+---------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Global_active_power\n",
    "df_new5 = df.filter(df.Global_active_power != '?')\n",
    "df_new5.select(mean(\"Global_active_power\"), stddev(\"Global_active_power\")).show(truncate=False)\n",
    "\n",
    "#Global_reactive_power\n",
    "df_new6 = df.filter(df.Global_reactive_power != '?')\n",
    "df_new6.select(mean(\"Global_reactive_power\"), stddev(\"Global_reactive_power\")).show(truncate=False)\n",
    "\n",
    "#Voltage\n",
    "df_new7 = df.filter(df.Voltage != '?')\n",
    "df_new7.select(mean(\"Voltage\"), stddev(\"Voltage\")).show(truncate=False)\n",
    "\n",
    "#Global_intensity\n",
    "df_new8 = df.filter(df.Global_intensity != '?')\n",
    "df_new8.select(mean(\"Global_intensity\"), stddev(\"Global_intensity\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b4202",
   "metadata": {},
   "source": [
    "【40pt】作業Part3: 執行min-max normalization來求出上述header(column)的normalized output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ce88e1",
   "metadata": {},
   "source": [
    "//開始處裡Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fc71eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|normalized global active power|\n",
      "+------------------------------+\n",
      "|          [0.3747963225473887]|\n",
      "|          [0.4783632318374359]|\n",
      "|          [0.47963065346431...|\n",
      "|          [0.4808980750911956]|\n",
      "|          [0.32500452429198...|\n",
      "+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------------------+\n",
      "|normalized global reactive power|\n",
      "+--------------------------------+\n",
      "|            [0.3007194366460509]|\n",
      "|            [0.3136690604292478]|\n",
      "|            [0.35827338206620...|\n",
      "|            [0.3611510643288495]|\n",
      "|            [0.3798561169588938]|\n",
      "+--------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+\n",
      "|  normalized voltage|\n",
      "+--------------------+\n",
      "|[0.37609048586059...|\n",
      "|[0.33699544306942...|\n",
      "|[0.32600960687537...|\n",
      "| [0.340549582688101]|\n",
      "|[0.4032309194863383]|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------------------------+\n",
      "|normalized global intensity|\n",
      "+---------------------------+\n",
      "|       [0.37759334108949...|\n",
      "|       [0.47302903063577...|\n",
      "|       [0.47302903063577...|\n",
      "|       [0.47302903063577...|\n",
      "|       [0.32365144595158...|\n",
      "+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "#1.original dataset\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"C://Users//user//Desktop//household_power_consumption//household_power_consumption.txt\")\n",
    "\n",
    "#抓出指定的column\n",
    "df_choose = df.select(\"Global_active_power\", \"Global_reactive_power\", \"Voltage\", \"Global_intensity\")\n",
    "\n",
    "#因為VectorAssembler不接受string型態的input，所以要把每個column的數據型態從String轉型為數字\n",
    "df=df_choose.withColumn(\"Global_active_power\", df.Global_active_power.astype(\"float\"))\n",
    "df=df.withColumn(\"Global_reactive_power\", df.Global_reactive_power.astype(\"float\"))\n",
    "df=df.withColumn(\"Voltage\", df.Voltage.astype(\"float\"))\n",
    "df=df.withColumn(\"Global_intensity\", df.Global_intensity.astype(\"float\"))\n",
    "\n",
    "#df.printSchema()\n",
    "#df.show(5)\n",
    "\n",
    "#把每個column分開來獨立成一個dataframe\n",
    "df1 = df.select(\"Global_active_power\")\n",
    "df2 = df.select(\"Global_reactive_power\")\n",
    "df3 = df.select(\"Voltage\")\n",
    "df4 = df.select(\"Global_intensity\")\n",
    "\n",
    "\n",
    "#2.Vector assembled set of features \n",
    "\n",
    "assembler1 = VectorAssembler(inputCols=[\"Global_active_power\"], outputCol=\"features1\", handleInvalid='skip')\n",
    "output1 = assembler1.transform(df1)\n",
    "\n",
    "assembler2 = VectorAssembler(inputCols=[\"Global_reactive_power\"], outputCol=\"features2\", handleInvalid='skip')\n",
    "output2 = assembler2.transform(df2)\n",
    "\n",
    "assembler3 = VectorAssembler(inputCols=[\"Voltage\"], outputCol=\"features3\", handleInvalid='skip')\n",
    "output3 = assembler3.transform(df3)\n",
    "\n",
    "assembler4 = VectorAssembler(inputCols=[\"Global_intensity\"], outputCol=\"features4\", handleInvalid='skip')\n",
    "output4 = assembler4.transform(df4)\n",
    "\n",
    "\n",
    "#3. Applying MinMaxScaler to my assembled features \n",
    "\n",
    "#會有4個output\n",
    "scaler = MinMaxScaler(inputCol=\"features1\", outputCol=\"normalized global active power\")\n",
    "# rescale each feature to range [min, max].\n",
    "scaledData1 = scaler.fit(output1).transform(output1)\n",
    "scaledData1.select(\"normalized global active power\").show(5)\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"features2\", outputCol=\"normalized global reactive power\")\n",
    "scaledData2 = scaler.fit(output2).transform(output2)\n",
    "scaledData2.select(\"normalized global reactive power\").show(5)\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"features3\", outputCol=\"normalized voltage\")\n",
    "scaledData3 = scaler.fit(output3).transform(output3)\n",
    "scaledData3.select(\"normalized voltage\").show(5)\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"features4\", outputCol=\"normalized global intensity\")\n",
    "scaledData4 = scaler.fit(output4).transform(output4)\n",
    "scaledData4.select(\"normalized global intensity\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d78444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
